{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Prompt Examples for Travel & Hospitality\n",
    "\n",
    "In this notebook, we include different example use cases for Travel & Hospitality using Amazon Bedrock.\n",
    "\n",
    "These sample use cases involve different tasks and prompt engeering techniques, as follows:\n",
    "1. **Generate recommendations based on metadata**\n",
    "    - **Task:** Text Generation\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "2. **Estimate capacity for airlines or hotel properties based on historical data**\n",
    "    - **Task:** Complex Reasoning\n",
    "    - **Prompt Technique:** Chain-of-Thoughts (CoT)\n",
    "3. **Create a question answering assistant for customer service**\n",
    "    - **Task:** Question Answering with Dialogue Asistant (without memory)\n",
    "    - **Prompt Technique:** Few-shot\n",
    "4. **Summarize and classify content from media files transcription**\n",
    "    - **Task:** Text Summarization & Text Classification\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "5. **Create splash pages describing upcoming promotions**\n",
    "    - **Task:** Code Generation\n",
    "    - **Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d5cb2-3c3a-4091-a11f-1df62d9e0d1d",
   "metadata": {},
   "source": [
    "Let's start by ensuring the Bedrock SDK is properly installed.\n",
    "\n",
    "We'll also install a few libraries required in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800edbd3-f31c-436c-93e4-a3e791c85549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!unzip ../bedrock-preview-documentation/SDK/bedrock-python-sdk.zip -d /root/bedrock\n",
    "\n",
    "#!pip install --upgrade pip\n",
    "#!pip install scikit-learn seaborn\n",
    "\n",
    "#!pwd\n",
    "#!python3 -m pip install /root/bedrock/boto3-1.26.142-py3-none-any.whl\n",
    "#!python3 -m pip install /root/bedrock/botocore-1.29.142-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3767a6-e9bb-4de4-a325-9d346b082402",
   "metadata": {},
   "source": [
    "Now we can import the libraries and setup the Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d82998-f5d1-4624-a54f-f9d04422b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "bedrock = boto3.client(\n",
    " service_name='bedrock',\n",
    " region_name='us-east-1',\n",
    " endpoint_url='https://bedrock.us-east-1.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ecac-8a9d-42b8-b1c7-8ecad5610314",
   "metadata": {},
   "source": [
    "Let's get the list of Foundational Models supported in Bedrock at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10722be-2f83-4f8c-89a4-7d9b181029f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f0d858da-ce48-42af-9236-79d0aab293f8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 27 Jun 2023 11:11:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '861',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f0d858da-ce48-42af-9236-79d0aab293f8'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05c03-98a6-4fc1-a288-1e43326383fe",
   "metadata": {},
   "source": [
    "We will define an utility function for calling Bedrock.\n",
    "\n",
    "This will help passing the proper body depending on the model invoked, and will store the results in a CSV file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968017bf-c186-4897-8a38-ecdbe276b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock(modelId, prompt_data):\n",
    "    if 'amazon' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt_data,\n",
    "            \"textGenerationConfig\":\n",
    "            {\n",
    "                \"maxTokenCount\":4096,\n",
    "                \"stopSequences\":[],\n",
    "                \"temperature\":0,\n",
    "                \"topP\":0.9\n",
    "            }\n",
    "        })\n",
    "        #modelId = 'amazon.titan-tg1-large'\n",
    "    elif 'anthropic' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"max_tokens_to_sample\": 4096,\n",
    "            \"stop_sequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"top_p\":0.9\n",
    "        })\n",
    "        #modelId = 'anthropic.claude-instant-v1'\n",
    "    elif 'ai21' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"maxTokens\":4096,\n",
    "            \"stopSequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"topP\":0.9\n",
    "        })\n",
    "        #modelId = 'ai21.j2-grande-instruct'\n",
    "    elif 'stability' in modelId:\n",
    "        body = json.dumps({\"text_prompts\":[{\"text\":prompt_data}]}) \n",
    "        #modelId = 'stability.stable-diffusion-xl'\n",
    "    else:\n",
    "        print('Parameter model must be one of titan, claude, j2, or sd')\n",
    "        return\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    if 'amazon' in modelId:\n",
    "        response = response_body.get('results')[0].get('outputText')\n",
    "    elif 'anthropic' in modelId:\n",
    "        response = response_body.get('completion')\n",
    "    elif 'ai21' in modelId:\n",
    "        response = response_body.get('completions')[0].get('data').get('text')\n",
    "\n",
    "    #Add interaction to the local CSV file...\n",
    "    #column_name = [\"timestamp\", \"modelId\", \"prompt\", \"response\", \"latency\"] #The name of the columns\n",
    "    #data = [datetime.now(), modelId, prompt_data, response, latency] #the data\n",
    "    #with open('./prompt-data/prompt-data.csv', 'a') as f:\n",
    "    #    writer = csv.writer(f)\n",
    "    #    #writer.writerow(column_name)\n",
    "    #    writer.writerow(data)\n",
    "    \n",
    "    return response, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa97f20-81c4-426c-b867-8400be5aea33",
   "metadata": {},
   "source": [
    "Now we are ready for running our examples with different models.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9ab5-e0ef-4741-b305-36053150e2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Generate recommendations based on metadata\n",
    "\n",
    "**Use Case:** A company wants to generate recommendations of flight destinations for their users based on some metadata, e.g. country, age-range, and interests.\n",
    "\n",
    "**Task:** Text Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382d9a5e-bb64-4af1-95dc-56f8a6ff3990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human:\n",
    "Generate a list of 10 recommended destinations for traveling considering the information in the <metadata></metadata> XML tags, and include a very brief description of each recommendation.\n",
    "\n",
    "<metadata>\n",
    "Passenger country is Spain\n",
    "Age range between 20-30\n",
    "Interested on water sports and theme parks\n",
    "Traveling during the summer\n",
    "</metadata>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e14520a-990d-46b0-a660-3ea1b5a0f75d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a list of 10 recommended destinations for traveling based on the provided metadata:\n",
      "\n",
      "1. Hawaii - Beautiful beaches, surfing, and vibrant culture. Home to massive water parks and theme parks. \n",
      "2. Bali, Indonesia - Exotic island with stunning beaches, jungles, and rice paddies. Plenty of opportunities for snorkeling, boating, and other watersports. Also home to an exciting theme park.\n",
      "3. Orlando, Florida - Theme park capital of the world, including Walt Disney World and Universal Studios. Also close to beautiful beaches on the Gulf coast. \n",
      "4. Costa Rica - Pristine natural scenery, rainforests, and beaches along both the Pacific and Caribbean coasts. Eco-friendly destination for watersports and adventure activities.  \n",
      "5. Dubai, UAE - Glamorous city in the desert with massive water parks, indoor skiing, and the world's tallest rollercoaster. Also a hub for boating, jet skiing, and other watersports.\n",
      "6. Queensland, Australia - Miles of beaches along the Great Barrier Reef, perfect for swimming, snorkeling, sailing, and surfing. Also home to major theme parks like Sea World, Dreamworld, and Wet'n'Wild.\n",
      "7. Phuket, Thailand - Thailand's largest island in the Andaman Sea with scenic beaches, watersports, boat tours, and the Phuket FantaSea cultural theme park.\n",
      "8. Barcelona, Spain - Stylish city on the Mediterranean coast with a popular beachfront and nearby theme park. Close to the resort town of Salou, which offers more beaches, watersports, and the PortAventura theme park.\n",
      "9. Canary Islands, Spain - Archipelago off the coast of Morocco with a subtropical climate, volcanic landscapes, and beaches. Major destinations like Tenerife and Gran Canaria offer watersports, boating, and theme parks like Siam Park and Loro Parque. \n",
      "10. Algarve, Portugal - Southern region of Portugal centered around the Algarve coast, featuring stunning beaches, caves, and opportunities for swimming, surfing, kayaking, and other watersports. Also home to Zoomarine and Aquashow theme parks. \n",
      "\n",
      " Inference time: 0:00:12.102331\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ebf06a-1cf5-450c-953e-1cd1abe70f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are 10 recommended destinations for traveling:\n",
      "\n",
      "Dubai - An ultramodern city with amazing architecture, shopping malls, and water parks.  \n",
      "\n",
      "Maldives - A tropical paradise with beautiful beaches, crystal clear water for snorkeling, and overwater bungalows.\n",
      "\n",
      "Orlando, Florida - Home to many theme parks like Disney World, Universal Studios, and SeaWorld with roller coasters and water rides.   \n",
      "\n",
      "Bali, Indonesia - Tropical island known for its beaches, surfing, water sports, and Hindu culture.\n",
      "\n",
      "Phuket, Thailand - Beautiful beaches, waterfalls, and islands for snorkeling and diving near Phuket's lively city.   \n",
      "\n",
      "Barcelona, Spain - Home city with beautiful architecture, beaches, and theme parks like PortAventura.\n",
      "\n",
      "Ibiza, Spain - Famous for nightlife but also has beautiful beaches and coves for swimming and water sports.\n",
      "\n",
      "Miami, Florida - Beaches, art deco architecture, theme parks like Wet n Wild, and many water activities.   \n",
      "\n",
      "Cancun, Mexico - Long stretches of white sand beaches, turquoise water for swimming, and water parks.\n",
      "\n",
      "Santorini, Greece - Stunning caldera views, beaches for swimming, and volcanic black sand beaches. \n",
      "\n",
      " Inference time: 0:00:03.779193\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847647f-94e4-4a47-9cd2-2609af023546",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde01ec0-52c2-471e-aaf4-b4803085f162",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Estimate capacity for airlines or hotel properties based on historical data\n",
    "\n",
    "**Use Case:** A T&H company wants to estimate capacity/occupancy levels they could have for the next days based on historical information and flights/hotels metadata.\n",
    "\n",
    "**Task:** Complex Reasoning\n",
    "\n",
    "**Prompt Technique:** Chain-of-Thoughts (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8993b8-2772-4c33-b17b-7fbddb9b7e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human: La semana pasada, los pasajeros de 3 rutas de una aerolínea fueron según los siguientes datos:\n",
    "- Lunes: Paris 650, New York 320, Singapore 415\n",
    "- Martes: Paris 640, New York 330, Singapore 410\n",
    "- Miércoles: Paris 630, New York 340, Singapore 425\n",
    "\n",
    "Pregunta: ¿Cuántos pasajeros podemos esperar el próximo Viernes en la ruta a Paris?\n",
    "Respuesta: Según los números dados y sin disponer de más información, hay una disminución diaria de 10 pasajeros para la ruta a Paris.\n",
    "Si asumimos que esta tendencia continuará durante los siguientes días, podemos esperar 620 pasajeros para el siguiente día que es Jueves y,\n",
    "por lo tanto, 610 pasajeros para el Viernes.\n",
    "\n",
    "Pregunta: ¿Cuántos pasajeros podemos esperar el Sábado en cada una de las rutas? razona paso a paso y provee recomendaciones para incrementar los pasajeros\n",
    "Assistant:\n",
    "Respuesta:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "732984e8-2c6d-4b45-9b77-90e856c2b10e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Ruta Paris: Según la tendencia de disminución de 10 pasajeros por día, para el Sábado podemos esperar 600 pasajeros.\n",
      "- Ruta New York: Según la tendencia de aumento de 10 pasajeros por día, para el Sábado podemos esperar 350 pasajeros.\n",
      "- Ruta Singapore: Según la tendencia de aumento de 5 pasajeros por día, para el Sábado podemos esperar 435 pasajeros.\n",
      "\n",
      "Recomendaciones para incrementar los pasajeros:\n",
      "\n",
      "1. Ofrecer promociones y descuentos para los pasajes de ese fin de semana, especialmente para las rutas con tendencia a la baja como Paris. Esto puede atraer a más pasajeros.\n",
      "\n",
      "2. Realizar campañas de marketing enfocadas en los destinos de esas rutas, promocionando los atractivos turísticos y actividades para hacer en esos lugares. Esto puede generar más interés en los pasajeros potenciales.\n",
      "\n",
      "3. Mejorar la experiencia de vuelo en esas rutas, por ejemplo ofreciendo mejores servicios a bordo, más comodidad, entretenimiento, etc. Una buena experiencia de vuelo puede fidelizar a los pasajeros e incentivar a más personas a elegir esa aerolínea y esas rutas.\n",
      "\n",
      "4. Analizar la competencia y los precios que ofrecen por esas rutas. Quizás los precios actuales no son muy competitivos y por eso no se atrae a más pasajeros. Se podrían ajustar los precios si es necesario.\n",
      "\n",
      "5. Hacer alianzas con otras aerolíneas para ofrecer mejores conexiones y enrutamientos a los pasajeros. Esto amplía las opciones de los pasajeros y puede incrementar el flujo de pasajeros para esas rutas. \n",
      "\n",
      " Inference time: 0:00:11.352548\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e8bc44-aa79-4bbd-b5b7-52be3c0f51d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la ruta a Paris:\n",
      "- El Lunes fueron 650 pasajeros\n",
      "- El Martes fueron 640 pasajeros, 10 menos que el Lunes \n",
      "- El Miércoles fueron 630 pasajeros, 10 menos que el Martes\n",
      "Si seguimos esta tendencia:\n",
      "- El Jueves serán 620 pasajeros, 10 menos que el Miércoles\n",
      "- El Viernes serán 610 pasajeros, 10 menos que el Jueves\n",
      "\n",
      "Para la ruta a New York:\n",
      "- El Lunes fueron 320 pasajeros\n",
      "- El Martes fueron 330 pasajeros, 10 más que el Lunes\n",
      "- El Miércoles fueron 340 pasajeros, 10 más que el Martes\n",
      "Si seguimos esta tendencia:\n",
      "- El Jueves serán 350 pasajeros, 10 más que el Miércoles\n",
      "- El Viernes serán 360 pasajeros, 10 más que el Jueves\n",
      "\n",
      "Para la ruta a Singapore:\n",
      "- El Lunes fueron 415 pasajeros  \n",
      "- El Martes fueron 410 pasajeros, 5 menos que el Lunes\n",
      "- El Miércoles fueron 425 pasajeros, 15 más que el Martes\n",
      "No hay una tendencia clara, así que no podemos predecir con precisión los pasajeros para el Jueves y Viernes.\n",
      "\n",
      "Recomendaciones para incrementar los pasajeros:\n",
      "- Ofertas y promociones \n",
      "- Mejorar la experiencia del cliente con más comodidad y entretenimiento a bordo\n",
      "- Ampliar la red de destinos \n",
      "- Mejorar la imagen de marca y presencia en redes sociales\n",
      "- Trabajar con agencias de viajes y turoperadores \n",
      "\n",
      " Inference time: 0:00:04.350620\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253149f-ae27-42d0-a36c-bd07fc22264c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f45c25-cb45-4d9d-8cb1-29b3547483b3",
   "metadata": {},
   "source": [
    "## 3. Create a question answering assistant for customer service\n",
    "\n",
    "**Use Case:** A company wants to create a bot capable of answering questions about the services available, based on the internal information for these.\n",
    "\n",
    "**Task:** Question Answering with Dialogue Asistant (no memory)\n",
    "\n",
    "**Prompt Technique:** Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b5cc7e9-876e-4d77-99cd-099439033148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Context: An airline services available for purchase are as follows\n",
    "1. Seat upgrades, available from 20 Euros, to classes Economy Plus and Business, on weekdays' flights\n",
    "2. Meals, available for payment in-flight, mediterranean menu, on all days' flights\n",
    "3. Fast boarding, from 30 Euros, available for premier customers, on all days' flights\n",
    "\n",
    "Instruction: Answer any questions about the services available in a friendly manner. If you don't know the answer just say 'Apologies, but I don't have the answer for that. Please contact our team by phone.'\n",
    "\n",
    "Assistant: Welcome to Airline Services, how can I help you?\n",
    "Human: Hi, I would like to know what are the services available please.\n",
    "Assistant: Of course, right now we have the seat upgrades, the meals, and the fast boarding.\n",
    "Human: Thank you. I would like to know details for those please.\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceae8a78-c7d2-470d-82da-8f08677cb469",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Certainly, here are the details for our available services:\n",
      "\n",
      "Seat upgrades:\n",
      "- Economy Plus upgrade: Extra legroom seats, available for 20 Euros on weekdays' flights. \n",
      "- Business class upgrade: Wider, more comfortable seats, available for 50-100 Euros depending on the route, on weekdays' flights.\n",
      "\n",
      "Meals:\n",
      "- Mediterranean menu: A selection of meals like pasta, pizza, paninis available for around 10 Euros, on all days' flights.\n",
      "\n",
      "Fast boarding:\n",
      "- For our premier customers, fast boarding option allows you to board the plane before general boarding, available for 30 Euros on all days' flights.\n",
      "\n",
      "Does this help explain our services? Let me know if you have any other questions. \n",
      "\n",
      " Inference time: 0:00:04.445540\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d63227-09c8-4ea6-bf13-712b837a934c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the details:\n",
      "\n",
      "1. Seat upgrades, available from 20 Euros, to classes Economy Plus and Business, on weekdays' flights. This allows you to move to a more spacious seat with extra legroom.\n",
      "\n",
      "2. Meals, available for payment in-flight, mediterranean menu, on all days' flights. You can choose from a selection of meals like pasta, salad, sandwiches, etc. \n",
      "\n",
      "3. Fast boarding, from 30 Euros, available for premier customers, on all days' flights. This allows you to board the plane before other passengers so you can get settled in quickly.\n",
      "\n",
      "Please let me know if you need any clarification or have additional questions. I'm happy to help. \n",
      "\n",
      " Inference time: 0:00:01.706800\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa69b-0ec0-4837-a019-fb16fca9fb0e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80a21f-7987-40d0-b923-193c72367f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Generate content summary based on transcriptions from media files\n",
    "\n",
    "**Use Case:** A company needs to generate summaries of the audio transcription for audio and video files for customer service, to be sent to their operations quality team. They also want to classify this content according to specific categories.\n",
    "\n",
    "**Task:** Text Summarization & Text Classification\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d510-d20d-4820-96d6-156977876859",
   "metadata": {},
   "source": [
    "#### (Pre-requisite)\n",
    "\n",
    "First, we will need to transcribe the media files. You can e.g. use Amazon Transcribe for this task following examples like this: https://docs.aws.amazon.com/code-library/latest/ug/transcribe_example_transcribe_StartTranscriptionJob_section.html\n",
    "\n",
    "For our sample we will start from an interview transcription in the file \"interview.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edaa1e2c-6de3-4b24-805f-2090fd7909b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy Fallon: (00:00)\n",
      "Thank you for doing This Christmas Will Be Different. I appreciate you doing that. We hung out all day together.\n",
      "\n",
      "Matthew McConaughey: (00:04)\n",
      "How fun was that?\n",
      "\n",
      "Jimmy Fallon: (00:05)\n",
      "It was the greatest. We always…\n",
      "\n",
      "Matthew McConaughey: (00:07)\n",
      "Two take maximum. Two take maximum.\n",
      "\n",
      "Jimmy Fallon: (00:09)\n",
      "We nailed it, we have some good takes. That was so much fun. Happy holidays to you and your family. I’m happy to see you in person. Thanks for making the trip and being here.\n",
      "\n",
      "Matthew McConaughey: (00:18)\n",
      "Absolutely.\n",
      "\n",
      "Jimmy Fallon: (00:19)\n",
      "Do you have like family traditions? Do you have holiday plans? What do you have coming up?\n",
      "\n",
      "Matthew McConaughey: (00:24)\n",
      "This year, we’re going to get all the McConaughey family. We’re also getting Camila’s family. So when we do that and we have that multicultural Christmas, Christmas lasts a long time at our place because they celebrate on the 24th. Midnight you exchange presents. All right. So you have the big sit down dinner, you get the china out for the first time all year. If it was up to my family, it’d be paper plates. Thank you, Camila for getting the china out and having a better ritual.\n",
      "\n",
      "Jimmy Fallon: (00:50)\n",
      "No, we are using china.\n",
      "\n",
      "Matthew McConaughey: (00:51)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (00:52)\n",
      "Thank you, Camila.\n",
      "\n",
      "Matthew McConaughey: (00:53)\n",
      "We do that that night. And then we get up the next day and we do our Christmas, which is everyone opens present. Santa came. The problem, the reason I say it’s longer already is that my mother who’s 90 still demands that everyone open their present and everyone watch one person open their present at the time.\n",
      "\n",
      "Jimmy Fallon: (01:09)\n",
      "Yeah. Yeah.\n",
      "\n",
      "Matthew McConaughey: (01:10)\n",
      "You’ve got a big Brazilian family, you’ve got a big McConaughey family, there’s a family of 20. There’s a lot of presents, thankfully. It may be dark on the 25th when we’re done opening presents from that morning. And so seven o’clock PM and you just finished opening presents from Christmas morning. So the nights get long.\n",
      "\n",
      "Jimmy Fallon: (01:26)\n",
      "My grandma used to do this thing where we would unwrap the presents. She goes, can you just not rip it just so I can reuse the wrapping.\n",
      "\n",
      "Matthew McConaughey: (01:32)\n",
      "Save the wrapping.\n",
      "\n",
      "Jimmy Fallon: (01:33)\n",
      "Save the wrap for the next year. I go, yes, okay, grandma.\n",
      "\n",
      "Matthew McConaughey: (01:36)\n",
      "It’s 3:00 PM.\n",
      "\n",
      "Jimmy Fallon: (01:36)\n",
      "Let’s go. Let’s open up the thing. Yeah. It’s so fun. I look forward to it. Are you a guy that makes New Year’s resolutions?\n",
      "\n",
      "Matthew McConaughey: (01:43)\n",
      "Yeah. I check in on myself.\n",
      "\n",
      "Jimmy Fallon: (01:46)\n",
      "You check in on yourself.\n",
      "\n",
      "Matthew McConaughey: (01:49)\n",
      "I asked myself to work on my patience last year on New Year’s Eve.\n",
      "\n",
      "Jimmy Fallon: (01:55)\n",
      "We all need to do that.\n",
      "\n",
      "Matthew McConaughey: (01:57)\n",
      "And now thank you for reminding me, I guess tonight, I’ll start thinking about how I’ve done the last 11 months.\n",
      "\n",
      "Jimmy Fallon: (02:01)\n",
      "Exactly right. Well, I think last time we talked, I mean, congratulations, your book, Green Lights, was on the New York Times’ bestseller list 50, 5-0, 50 weeks. It sold like two and a half million copies. It is a giant, giant hit. But congratulations. I loved it.\n",
      "\n",
      "Matthew McConaughey: (02:18)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (02:19)\n",
      "Did you realize it would take off like that? I mean so many people.\n",
      "\n",
      "Matthew McConaughey: (02:22)\n",
      "I had no idea.\n",
      "\n",
      "Jimmy Fallon: (02:23)\n",
      "It’s massive.\n",
      "\n",
      "Matthew McConaughey: (02:24)\n",
      "It hit a nerve. Thank you everyone out there who had a read of it.\n",
      "\n",
      "Jimmy Fallon: (02:29)\n",
      "It was so honest and it was so… I loved it. I told you as soon as I read it, I couldn’t stop reading it. I go, oh, it’s so personal, but it’s so also universal.\n",
      "\n",
      "Matthew McConaughey: (02:39)\n",
      "Yep. I think that’s what people got from it. People said, hey, I see myself and you, I see my stories in your stories. And it kind of lays out a map of process. It’s a process book. It’s not a product book. It’s a approach to life with this rodeo we’re all trying to get through and trying to get our eight seconds on. How can we do our best to get it?\n",
      "\n",
      "Jimmy Fallon: (02:59)\n",
      "You’re coming out with a journal now, a companion journal to help people. Because I think you were saying in the book too, it’s tough when you write to just tell someone, hey, just write something down every day or every night.\n",
      "\n",
      "Matthew McConaughey: (03:12)\n",
      "A blank sheet of paper intimidates the heck out of us. Right?\n",
      "\n",
      "Jimmy Fallon: (03:15)\n",
      "It does.\n",
      "\n",
      "Matthew McConaughey: (03:15)\n",
      "But journaling or writing things down I’ve done it all my life and it’s how I wrote Green Lights the book. Immensely valuable. I mean, I write things down to forget. If you write them down, you can forget them because they’re in there. Don’t just go to the diary or the journal to write down when you’re frustrated and confused. Go to the journal to write down what you’re doing in life when you’re rolling, when you’re catching green lights, when you’re in the flow, because we will get out of flow again. And it’s nice to have a document to go back and go, hoo, what was I doing when I was cruising?\n",
      "\n",
      "Jimmy Fallon: (03:44)\n",
      "Yeah. When life was perfect there in that moment.\n",
      "\n",
      "Matthew McConaughey: (03:46)\n",
      "You see habits and you can change and recalibrate. But yeah, it’s a journal. I got little nudges along the way that kind of help you and ask you some questions to write your story. The book Green Lights was my story. This is for your story.\n",
      "\n",
      "Jimmy Fallon: (03:57)\n",
      "Ah, I love that buddy. That’s awesome. Congrats on that.\n",
      "\n",
      "Matthew McConaughey: (04:02)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (04:03)\n",
      "We also, you were nice enough to Zoom into us when we couldn’t get any guests anywhere. No one was allowed to travel or do anything, but there was talk of you maybe running for governor of Texas and you recently decided to not run for governor.\n",
      "\n",
      "Matthew McConaughey: (04:17)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (04:17)\n",
      "Can you walk us through that decision?\n",
      "\n",
      "Matthew McConaughey: (04:19)\n",
      "Well, it was a to two year consideration that I came to the decision really over the last couple of months. And I was asking myself the original question and trying to answer it, how and where and what can I do to be most useful to myself, to my family and to the most amount of people. The embassy, the category of politics came up and it’s a privileged one that I gave great consideration to. But at this point in my life are the things I’ve got a 13 year old, 11 year old and an eight year old, the life I’m living right now, the storytelling I want to keep doing, it’s not the category for me at this point in my life.\n",
      "\n",
      "Jimmy Fallon: (04:51)\n",
      "Still not ruling out future.\n",
      "\n",
      "Matthew McConaughey: (04:53)\n",
      "I’m not until I am.\n",
      "\n",
      "Jimmy Fallon: (04:55)\n",
      "Okay.\n",
      "\n",
      "Matthew McConaughey: (04:56)\n",
      "Someone told me that was a very McConaughey answer the other day.\n",
      "\n",
      "Jimmy Fallon: (04:59)\n",
      "Not until I am. It’s very, yeah.\n",
      "\n",
      "Matthew McConaughey: (05:02)\n",
      "I’ll be keeping an eye open for-\n",
      "\n",
      "Jimmy Fallon: (05:03)\n",
      "Because I know Texas loves you. And when we did the show from Texas, you were nice enough to come on the show and gosh, you’re beloved down there as well. You think people love you here, standing ovations. They love you there.\n",
      "\n",
      "Matthew McConaughey: (05:15)\n",
      "It’s a great state.\n",
      "\n",
      "Jimmy Fallon: (05:16)\n",
      "I know you put on a benefit concert. What’s [inaudible 00:05:20] We’re Texas. After that rough, awful, devastating…\n",
      "\n",
      "Matthew McConaughey: (05:25)\n",
      "Winter storm Uru came through. We’re not used to winter storms like that in Texas. Okay. We were a bit awkward. We weren’t prepared. And a lot of people were out of home. A lot of people were out of school. A lot of people needed some help because they didn’t know how to deal with it. And so we, my foundation, which is the Just Keep Livin Foundations, we got together and said, we’re not disaster relief, but want to be disaster relief. We said, let’s go. And I headed to Texas. I got on the phone, Camilla got on the phone. 100% of the people we called, whether it was companies who donated, whether it was musicians who came in, everybody was a yes in the first 30 seconds. We went down to Texas, put the show on. We raised over $7.7 million, which is still being put out to our community.\n",
      "\n",
      "Jimmy Fallon: (06:05)\n",
      "That’s how you do it right there. You just stepped up. And I go, oh my gosh, what do you know about putting on a live concert? You’re like, nothing.\n",
      "\n",
      "Matthew McConaughey: (06:12)\n",
      "It was like takes today. You get one take, two maximum, but let’s throw it together. Because you have to. Disaster relief, you have to move quickly because if you take your time to say, oh, this has got to be perfect. Something else is taking the front page news. There’s another disaster coming, you know? So you need to jump on it quickly and get everyone together and take advantage of trying to get people to give at that time when it is front page news and they know people need help.\n",
      "\n",
      "Jimmy Fallon: (06:36)\n",
      "I saw Hollywood Reporter named you philanthropist of the year with all the stuff you do to give back.\n",
      "\n",
      "Matthew McConaughey: (06:41)\n",
      "That was cool.\n",
      "\n",
      "Jimmy Fallon: (06:44)\n",
      "It’s good to be you, but it’s also great to give back and it’s great. You know what you do? You show up. Every time you always show up for me, but I think for anything. I know you’re a great dad.\n",
      "\n",
      "Matthew McConaughey: (06:56)\n",
      "Thank you. Try to. I think we all try to. I think we learn more and more as we age, we serve ourself when we do serve others. That is a reciprocity little exchange right there. And then also there’s ways to serve ourself and serve others at the same time and where those two meet when we’re filling our bank account and our souls account at the same time, we’re getting the quantity and the quality at the same time. Honey, ho.\n",
      "\n",
      "Jimmy Fallon: (07:20)\n",
      "That’s what I’m talking about. I want to talk about and show a clip from Sing 2. More with Matthew McConaughey when we come back. Everybody come on back.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"interview.txt\", \"r\").read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e6dea9-7ae5-42ae-8195-b670e36d1482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =f\"\"\"\n",
    "Human:\n",
    "Generate a summary of the transcription in the <transcription></transcription> XML tags below.\n",
    "Then, classify the mood of the participants according to the closest category within 'fully satisfied', 'satisfied', 'unsatisfied', 'fully unsatisfied', or 'neutral'.\n",
    "\n",
    "<transcription>\n",
    "{f}\n",
    "</transcription>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "770b5b1d-d553-4526-8892-ec9f4570f731",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "Jimmy Fallon and Matthew McConaughey discuss McConaughey's holiday plans, family traditions, and philanthropic work. McConaughey talks about celebrating Christmas with both his and his wife Camila's extended families, which results in long days of present opening and meals. Fallon and McConaughey bond over memories of saving wrapping paper and impatiently waiting to open presents with family. \n",
      "\n",
      "McConaughey discusses his decision not to run for Texas governor at this point to focus on his family and storytelling. However, he does not rule out running for political office in the future. McConaughey also talks about organizing a benefit concert that raised over $7 million for Texans affected by Winter Storm Uri. Fallon praises McConaughey for his philanthropic work and showing up to help others in times of need.\n",
      "\n",
      "Overall, the mood of the participants seems satisfied and content discussing family, charity work, and life events. The friendly, casual tone and laughter throughout the conversation indicates Fallon and McConaughey are fully satisfied with their discussion. \n",
      "\n",
      " Inference time: 0:00:09.338650\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d09320-6f1e-4596-8f51-55dfc0b127d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "- Jimmy Fallon and Matthew McConaughey discuss Matthew filming a Christmas song for Jimmy's show. They had fun filming it together.\n",
      "\n",
      "- Matthew talks about his family's Christmas traditions which involve both his and his wife's large extended families. They celebrate on Christmas Eve and Christmas Day, so the celebrations last a long time. \n",
      "\n",
      "- They discuss New Year's resolutions and Matthew says his resolution last year was to work on his patience. \n",
      "\n",
      "- Jimmy congratulates Matthew on the success of his book \"Green Lights\" which was a New York Times bestseller for 50 weeks and sold over 2.5 million copies. Matthew says he had no idea it would be so successful but it hit a nerve with people.\n",
      "\n",
      "- They discuss Matthew's new companion journal to his book to help people journal their own stories. \n",
      "\n",
      "- Matthew considered running for governor of Texas but recently decided not to run, citing his young children and wanting to focus on storytelling at this point in his life. \n",
      "\n",
      "- Matthew organized a benefit concert in Texas after a winter storm to raise money for disaster relief, which raised over $7 million.\n",
      "\n",
      "- In summary, the mood of the conversation seems 'fully satisfied'. The participants are enjoying their discussion, congratulating each other on successes, and discussing positive life events and charitable work in a cheerful manner. \n",
      "\n",
      " Inference time: 0:00:05.302026\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410031e-d47f-485f-b83e-cbdbbb2fa42b",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617cee-a8e9-4728-b821-6ebf2c6d51fc",
   "metadata": {},
   "source": [
    "## 5. Create splash pages describing upcoming promotions\n",
    "\n",
    "**Use Case:** A company wants to create HTML pages quickly and easily for their upcoming promotions.\n",
    "\n",
    "**Task:** Code Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e248a2a2-687b-40c5-aeed-e183bd181b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "There is an upcoming promotion presented by the Spanish Wings airline.\n",
    "The promotion is targeting young audience in the age range between 18 and 40.\n",
    "The promotion consists of a 20% discount when purchasing tickets online.\n",
    "There will be additional fees for seat assignment and tickets can be bought trought this same portal.\n",
    "The promotion is part of the Summer Discounts of the company.\n",
    "The promotion is available from June 28th to August 31st.\n",
    "\n",
    "Based the this information, generate the HTML code for an attractive splash page for this promotion.\n",
    "Include catchy phrases and invite customers to sign-up for the airlines' loyalty program.\n",
    "Have the splash page use yellow fonts and black background, according to the airlines' branding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f4a927-6e7a-49fd-b253-6ee555b17fbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Here is a draft HTML code for the splash page:\n",
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Spanish Wings Summer Promotion</title> \n",
       "<style>\n",
       "body {\n",
       "background-color: black;\n",
       "color: yellow; \n",
       "font-family: Helvetica, sans-serif;\n",
       "}\n",
       "h1 {\n",
       "font-size: 60px;\n",
       "}\n",
       "p {\n",
       "font-size: 20px;\n",
       "}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<h1>20% OFF THIS SUMMER!</h1>\n",
       "<p>Young travelers, this one's for you! From June 28 to August 31, get 20% off when you book on <span style=\"color:red;\">spanishwings.com</span>.</p>\n",
       "<p>Escape the heat and discover new destinations. Adventure awaits!</p>  \n",
       "<button style=\"background-color: yellow; color: black; font-size: 25px;\">Sign up for our loyalty program today!</button> \n",
       "<p>Additional baggage and seat selection fees may apply. Discount applies to base fare only.</p>\n",
       "<img src=\"beach.jpg\" width=\"600\" height=\"400\">\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbf6f2f2-601e-4da8-bf2f-ec1ef4840faf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "<body style=\"background-color:black;\">\n",
       "<center>\n",
       "<h1 style=\"color:yellow;\">Fly Now, Pay Less with Spanish Wings!</h1>\n",
       "<p style=\"color:yellow;\">Get 20% off your next flight when you book online now.</p>\n",
       "<p style=\"color:yellow;\">Hurry, offer ends August 31!</p> \n",
       "<p style=\"color:yellow;\">Sign up for our loyalty program and earn points on every flight.</p>\n",
       "<form>\n",
       "<input style=\"color:yellow;\" type=\"email\" placeholder=\"Enter email\"> \n",
       "<input style=\"color:yellow;\" type=\"submit\" value=\"Sign Me Up!\">\n",
       "</form>  \n",
       "</center>\n",
       "</body>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097551eb-61a2-4134-a016-eacce0e751e4",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5d15e-4dec-40e7-b5d8-708e563f35bf",
   "metadata": {},
   "source": [
    "## 6. Analyze machines' sensor data for predictive maintenance\n",
    "\n",
    "**Use Case:** A company wants to analyze distributions and other factors from machines' sensor data collected for preparing in predictive maintenance.\n",
    "\n",
    "**Task:** Data Analysis\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2445eb-2434-42fc-b67d-1c9576806cad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>machine</th>\n",
       "      <th>event</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>407438</td>\n",
       "      <td>215630672</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F0166B</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>403174</td>\n",
       "      <td>61370680</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>237394</td>\n",
       "      <td>173295968</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01JE0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>410186</td>\n",
       "      <td>79694024</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>S1F01R2B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>313173</td>\n",
       "      <td>135970480</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124489</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>Z1F0MA1S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>353705</td>\n",
       "      <td>18310224</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124490</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>Z1F0Q8RT</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "      <td>332792</td>\n",
       "      <td>172556680</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124491</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>Z1F0QK05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350410</td>\n",
       "      <td>19029120</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124492</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>Z1F0QL3N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>358980</td>\n",
       "      <td>226953408</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124493</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>Z1F0QLC1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351431</td>\n",
       "      <td>17572840</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124494 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   machine  event  feature1  feature2  feature3   feature4   \n",
       "0       2015-01-01  S1F01085      0         0         7    407438  215630672  \\\n",
       "1       2015-01-01  S1F0166B      0         3         0    403174   61370680   \n",
       "2       2015-01-01  S1F01E6Y      0         0         0    237394  173295968   \n",
       "3       2015-01-01  S1F01JE0      0         0         0    410186   79694024   \n",
       "4       2015-01-01  S1F01R2B      0         0         3    313173  135970480   \n",
       "...            ...       ...    ...       ...       ...       ...        ...   \n",
       "124489  2015-11-02  Z1F0MA1S      0         0         0    353705   18310224   \n",
       "124490  2015-11-02  Z1F0Q8RT      0       107        13    332792  172556680   \n",
       "124491  2015-11-02  Z1F0QK05      0         0         0    350410   19029120   \n",
       "124492  2015-11-02  Z1F0QL3N      0         0         0    358980  226953408   \n",
       "124493  2015-11-02  Z1F0QLC1      0         0         0    351431   17572840   \n",
       "\n",
       "        feature5  feature6  feature7  feature8  feature9  \n",
       "0              6         0        52        56       0.0  \n",
       "1              6         0         0         0       0.0  \n",
       "2             12         0         0         0       0.0  \n",
       "3              6         0         0         0       0.0  \n",
       "4             15         0         0         0       0.0  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "124489        10         8         0         0      12.0  \n",
       "124490        11         0         4        96       0.0  \n",
       "124491        11         0         0      4832       0.0  \n",
       "124492        12         0         0         0       0.0  \n",
       "124493        10         0         0         0       0.0  \n",
       "\n",
       "[124494 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "machine = pd.read_csv('machine_event.csv')\n",
    "machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3ec63a5-8a23-4a1f-9a39-572ba62ac9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data=f\"\"\"\n",
    "Context: Act as an expert data-analyst of a railways' company considering the data in the <data></data> XML tags below.\n",
    "The data contains metrics collected from the sensors in different machines, having failure events included in the \"event\" field as non-zero values.\n",
    "\n",
    "<data>\n",
    "{machine}\n",
    "</data>\n",
    "\n",
    "Human: What is the distribution in each one of the features?\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89f384e4-b844-468c-a6c8-288df500e1a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the distributions for each feature in the data:\n",
      "\n",
      "feature1: Mostly zeros, with a few non-zero values up to 107. Skewed distribution.\n",
      "feature2: Mostly zeros, with a few non-zero values up to 13. Skewed distribution.\n",
      "feature3: Values range from 237394 to 410186. Relatively normal distribution.\n",
      "feature4: Values range from 61370680 to 226953408. Relatively normal distribution. \n",
      "feature5: Values range from 6 to 15. Skewed distribution.\n",
      "feature6: Mostly zeros, with a few non-zero values up to 8. Skewed distribution.\n",
      "feature7: Mostly zeros, with a few non-zero values up to 4. Skewed distribution.\n",
      "feature8: Mostly zeros, with a few non-zero values up to 96 and 4832. Bimodal distribution.\n",
      "feature9: Values range from 0 to 12. Skewed distribution.\n",
      "\n",
      "So in summary, features 1, 2, 5, 6, 7 and 9 have skewed distributions with most values being 0. Features 3, 4 and 8 have more normal distributions. \n",
      "\n",
      " Inference time: 0:00:06.252443\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b202460b-d7dd-4842-9e5e-6bf161d68d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = prompt_data + response + \"\"\"\n",
    "Human: Estimate when the next failure is most likely to happen and in which machine\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "777180cd-2e7e-49b1-9129-f42c73cd1acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To estimate when the next failure is likely to happen, we can look at the pattern of non-zero \"event\" values in the data. The last non-zero event value is at index 124492, on 2015-11-02 for machine Z1F0QL3N. Since failures seem to happen sporadically in the data, a reasonable estimate for the next failure would be within the next month, around December 2015.\n",
      "\n",
      "To determine which machine is most at risk of failure, we can look at the feature values for the machines around the time of the last failure. The machines with feature values most similar to Z1F0QL3N at index 124492 would be most at risk. The 3 machines most similar in their feature values at that point in time are:\n",
      "\n",
      "1. Z1F0MA1S - Very similar values for features 3 through 9. \n",
      "2. Z1F0Q8RT - Also quite similar for features 3 through 9, though feature 2 is higher. \n",
      "3. Z1F0QLC1 - Again quite similar for features 3 through 9.\n",
      "\n",
      "So based on the feature values and patterns in the data, I would estimate the next failure to likely happen in December 2015, and to likely affect one of the machines Z1F0MA1S, Z1F0Q8RT or Z1F0QLC1.\n",
      "\n",
      "Of course, there is uncertainty in these estimates, but based on the available data, these seem to be reasonable predictions. More data over time would help increase the accuracy of failure predictions. \n",
      "\n",
      " Inference time: 0:00:10.942819\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c45ec6-8934-4a2e-a53c-03ffa81ddd31",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
