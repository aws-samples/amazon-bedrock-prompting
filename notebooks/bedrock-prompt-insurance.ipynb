{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Prompt Examples for Insurance\n",
    "\n",
    "In this notebook, we include different example use cases for Insurance using Amazon Bedrock.\n",
    "\n",
    "These sample use cases involve different tasks and prompt engeering techniques, as follows:\n",
    "1. **Generate recommendations based on metadata**\n",
    "    - **Task:** Text Generation\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "2. **Estimate people insured for given policies based on historical data**\n",
    "    - **Task:** Complex Reasoning\n",
    "    - **Prompt Technique:** Chain-of-Thoughts (CoT)\n",
    "3. **Create a question answering assistant for customer service**\n",
    "    - **Task:** Question Answering with Dialogue Asistant (without memory)\n",
    "    - **Prompt Technique:** Few-shot\n",
    "4. **Summarize and classify content from media files transcription**\n",
    "    - **Task:** Text Summarization & Text Classification\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "5. **Create splash pages describing upcoming promotions**\n",
    "    - **Task:** Code Generation\n",
    "    - **Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d5cb2-3c3a-4091-a11f-1df62d9e0d1d",
   "metadata": {},
   "source": [
    "Let's start by ensuring the Bedrock SDK is properly installed.\n",
    "\n",
    "We'll also install a few libraries required in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800edbd3-f31c-436c-93e4-a3e791c85549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!unzip ../bedrock-preview-documentation/SDK/bedrock-python-sdk.zip -d /root/bedrock\n",
    "\n",
    "#!pip install --upgrade pip\n",
    "#!pip install scikit-learn seaborn\n",
    "\n",
    "#!pwd\n",
    "#!python3 -m pip install /root/bedrock/boto3-1.26.142-py3-none-any.whl\n",
    "#!python3 -m pip install /root/bedrock/botocore-1.29.142-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3767a6-e9bb-4de4-a325-9d346b082402",
   "metadata": {},
   "source": [
    "Now we can import the libraries and setup the Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d82998-f5d1-4624-a54f-f9d04422b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "bedrock = boto3.client(\n",
    " service_name='bedrock',\n",
    " region_name='us-east-1',\n",
    " endpoint_url='https://bedrock.us-east-1.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ecac-8a9d-42b8-b1c7-8ecad5610314",
   "metadata": {},
   "source": [
    "Let's get the list of Foundational Models supported in Bedrock at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10722be-2f83-4f8c-89a4-7d9b181029f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e26ee9bd-11bb-47c8-b9c5-e8670d7ec8fe',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 27 Jun 2023 15:41:04 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '861',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'e26ee9bd-11bb-47c8-b9c5-e8670d7ec8fe'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05c03-98a6-4fc1-a288-1e43326383fe",
   "metadata": {},
   "source": [
    "We will define an utility function for calling Bedrock.\n",
    "\n",
    "This will help passing the proper body depending on the model invoked, and will store the results in a CSV file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968017bf-c186-4897-8a38-ecdbe276b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock(modelId, prompt_data):\n",
    "    if 'amazon' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt_data,\n",
    "            \"textGenerationConfig\":\n",
    "            {\n",
    "                \"maxTokenCount\":4096,\n",
    "                \"stopSequences\":[],\n",
    "                \"temperature\":0,\n",
    "                \"topP\":0.9\n",
    "            }\n",
    "        })\n",
    "        #modelId = 'amazon.titan-tg1-large'\n",
    "    elif 'anthropic' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"max_tokens_to_sample\": 4096,\n",
    "            \"stop_sequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"top_p\":0.9\n",
    "        })\n",
    "        #modelId = 'anthropic.claude-instant-v1'\n",
    "    elif 'ai21' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"maxTokens\":4096,\n",
    "            \"stopSequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"topP\":0.9\n",
    "        })\n",
    "        #modelId = 'ai21.j2-grande-instruct'\n",
    "    elif 'stability' in modelId:\n",
    "        body = json.dumps({\"text_prompts\":[{\"text\":prompt_data}]}) \n",
    "        #modelId = 'stability.stable-diffusion-xl'\n",
    "    else:\n",
    "        print('Parameter model must be one of titan, claude, j2, or sd')\n",
    "        return\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    if 'amazon' in modelId:\n",
    "        response = response_body.get('results')[0].get('outputText')\n",
    "    elif 'anthropic' in modelId:\n",
    "        response = response_body.get('completion')\n",
    "    elif 'ai21' in modelId:\n",
    "        response = response_body.get('completions')[0].get('data').get('text')\n",
    "\n",
    "    return response, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa97f20-81c4-426c-b867-8400be5aea33",
   "metadata": {},
   "source": [
    "Now we are ready for running our examples with different models.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9ab5-e0ef-4741-b305-36053150e2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Generate recommendations based on metadata\n",
    "\n",
    "**Use Case:** A company wants to generate recommendations of insurance policies for their users based on some metadata, e.g. country, age-range, and interests.\n",
    "\n",
    "**Task:** Text Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "382d9a5e-bb64-4af1-95dc-56f8a6ff3990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human:\n",
    "Generate a list of 3 recommended insurance policies for a customer considering the information in the <metadata></metadata> XML tags, and include a very brief description of each recommendation.\n",
    "\n",
    "<metadata>\n",
    "Lives in Spain\n",
    "Age range between 20-30\n",
    "Owns a house\n",
    "Owns a car\n",
    "</metadata>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e14520a-990d-46b0-a660-3ea1b5a0f75d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are 3 recommended insurance policies with brief descriptions:\n",
      "\n",
      "1. Homeowners insurance - Provides coverage for damage to the home from events like fire, theft, or natural disasters. Important for a homeowner.\n",
      "\n",
      "2. Auto insurance - Liability and comprehensive coverage for the vehicle. Required for car owners.  \n",
      "\n",
      "3. Life insurance - Provides financial protection for dependents in the event of the policyholder's death. Recommended for young homeowners, especially if there are dependents. \n",
      "\n",
      " Inference time: 0:00:02.706645\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ebf06a-1cf5-450c-953e-1cd1abe70f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are 3 recommended insurance policies:\n",
      "\n",
      "Home insurance: Covers damage to your house from events like fire, theft, and weather damage. \n",
      "\n",
      "Car insurance: Legally required in Spain, covers repairs or replacement of your car if damaged or stolen.  \n",
      "\n",
      "Life insurance: Provides financial assistance to your beneficiaries in the event of your death, recommended at your age. \n",
      "\n",
      " Inference time: 0:00:01.193024\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847647f-94e4-4a47-9cd2-2609af023546",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde01ec0-52c2-471e-aaf4-b4803085f162",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Estimate capacity for airlines or hotel properties based on historical data\n",
    "\n",
    "**Use Case:** An insurance company wants to estimate contracted policies they could have for the next days based on historical information and metadata.\n",
    "\n",
    "**Task:** Complex Reasoning\n",
    "\n",
    "**Prompt Technique:** Chain-of-Thoughts (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f8993b8-2772-4c33-b17b-7fbddb9b7e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human: La semana pasada, los asegurados de 3 productos de pólizas de seguro de una empresa fueron según los siguientes datos:\n",
    "- Lunes: Vida 65000, Auto 32000, Hogar 41500\n",
    "- Martes: Vida 64000, Auto 33000, Hogar 41000\n",
    "- Miércoles: Vida 63000, Auto 34000, Hogar 42500\n",
    "\n",
    "Pregunta: ¿Cuántos asegurados podemos esperar el próximo Viernes para la póliza de Vida?\n",
    "Respuesta: Según los números dados y sin disponer de más información, hay una disminución diaria de 1000 asegurados para la póliza de Vida.\n",
    "Si asumimos que esta tendencia continuará durante los siguientes días, podemos esperar 62000 asegurados en la póliza de Vida para el siguiente día que es Jueves y,\n",
    "por lo tanto, 61000 asegurados para el Viernes.\n",
    "\n",
    "Pregunta: ¿Cuántos asegurados podemos esperar el Sábado en cada una de los productos? razona paso a paso y provee recomendaciones para incrementar los asegurados\n",
    "Assistant:\n",
    "Respuesta:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732984e8-2c6d-4b45-9b77-90e856c2b10e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vida: \n",
      "Lunes: 65000\n",
      "Martes: 64000, disminución de 1000\n",
      "Miércoles: 63000, disminución de 1000\n",
      "Jueves (estimado): 62000, disminución de 1000\n",
      "Viernes (estimado): 61000, disminución de 1000\n",
      "Sábado (estimado): 60000, disminución de 1000\n",
      "\n",
      "Auto:\n",
      "Lunes: 32000\n",
      "Martes: 33000, aumento de 1000 \n",
      "Miércoles: 34000, aumento de 1000\n",
      "Jueves (estimado): 35000, aumento de 1000\n",
      "Viernes (estimado): 36000, aumento de 1000\n",
      "Sábado (estimado): 37000, aumento de 1000\n",
      "\n",
      "Hogar: \n",
      "Lunes: 41500\n",
      "Martes: 41000, disminución de 500\n",
      "Miércoles: 42500, aumento de 1500\n",
      "Jueves (estimado): 41500, disminución de 1000 (promedio de cambio de Martes y Miércoles)\n",
      "Viernes (estimado): 41500, sin cambio\n",
      "Sábado (estimado): 41500, sin cambio\n",
      "\n",
      "Recomendaciones:\n",
      "- Ofrecer promociones o descuentos para atraer nuevos asegurados, especialmente para la póliza de Vida donde se observa una disminución.\n",
      "- Mejorar el servicio al cliente para retener los asegurados actuales. \n",
      "- Diversificar los canales de venta, por ejemplo a través de alianzas con otros negocios.\n",
      "- Analizar las razones de la disminución/aumento de asegurados para tomar acciones correctivas.\n",
      "- Monitorear las tendencias de asegurados diariamente para detectar cambios y reaccionar rápidamente. \n",
      "\n",
      " Inference time: 0:00:10.278810\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e8bc44-aa79-4bbd-b5b7-52be3c0f51d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para la póliza de Vida:\n",
      "- El lunes hubo 65000 asegurados\n",
      "- El martes hubo 64000 asegurados, una disminución de 1000 asegurados\n",
      "- El miércoles hubo 63000 asegurados, otra disminución de 1000 asegurados\n",
      "Siguiendo esta tendencia, podemos esperar:\n",
      "- El jueves 62000 asegurados (disminución de 1000)\n",
      "- El viernes 61000 asegurados (disminución de 1000)\n",
      "- El sábado 60000 asegurados (disminución adicional de 1000)\n",
      "\n",
      "Para la póliza de Auto:\n",
      "- El lunes hubo 32000 asegurados\n",
      "- El martes hubo 33000 asegurados, un aumento de 1000 asegurados \n",
      "- El miércoles hubo 34000 asegurados, otro aumento de 1000 asegurados\n",
      "Siguiendo esta tendencia, podemos esperar:\n",
      "- El jueves 35000 asegurados (aumento de 1000)\n",
      "- El viernes 36000 asegurados (aumento de 1000) \n",
      "- El sábado 37000 asegurados (aumento adicional de 1000)\n",
      "\n",
      "Para la póliza de Hogar:\n",
      "- El lunes hubo 41500 asegurados  \n",
      "- El martes hubo 41000 asegurados, una disminución de 500 asegurados\n",
      "- El miércoles hubo 42500 asegurados, un aumento de 1500 asegurados\n",
      "Sin una tendencia clara, es difícil predecir los números para el jueves, viernes y sábado.\n",
      "\n",
      "Para incrementar los asegurados, la empresa podría implementar campañas de marketing, ofrecer descuentos, mejorar el servicio al cliente, ampliar la cobertura, etc. Esto ayudaría a atraer y retener más clientes. \n",
      "\n",
      " Inference time: 0:00:04.670147\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253149f-ae27-42d0-a36c-bd07fc22264c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f45c25-cb45-4d9d-8cb1-29b3547483b3",
   "metadata": {},
   "source": [
    "## 3. Create a question answering assistant for customer service\n",
    "\n",
    "**Use Case:** A company wants to create a bot capable of answering questions about the services available, based on the internal information for these.\n",
    "\n",
    "**Task:** Question Answering with Dialogue Asistant (no memory)\n",
    "\n",
    "**Prompt Technique:** Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b5cc7e9-876e-4d77-99cd-099439033148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Context: An insurance company offers the following packages for contracting a travel insurance policy:\n",
    "1. International Plan, price is USD 10 per day, includes travel inconvenience, medical, presonal accident, and COVID protection \n",
    "2. Domestic Plan, price is USD 3 per day, includes medical without COVID, and personal accidents\n",
    "\n",
    "Instruction: Answer any questions about the services available in a friendly manner. If you don't know the answer just say 'Apologies, but I don't have the answer for that. Please contact our team by phone.'\n",
    "\n",
    "Assistant: Welcome to Smily Insurance, how can I help you?\n",
    "Human: Hi, I would like to know what are the travel insurance options available please.\n",
    "Assistant: Of course, right now we have the Domestic Plan and the International Plan.\n",
    "Human: Thank you. I would like to know details for those please.\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceae8a78-c7d2-470d-82da-8f08677cb469",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Certainly, here are the details for our travel insurance plans:\n",
      "\n",
      "International Plan:\n",
      "- Price: USD 10 per day of travel\n",
      "- Coverage includes:\n",
      "    - Travel inconvenience: Trip cancellation/interruption, missed connections, etc. \n",
      "    - Medical: Emergency medical expenses, hospitalization, repatriation of remains, etc.\n",
      "    - Personal accident: Accidental death or permanent disability \n",
      "    - COVID-19: Medical expenses related to COVID-19 diagnosis \n",
      "- Suitable for international travel outside your home country\n",
      "\n",
      "Domestic Plan:\n",
      "- Price: USD 3 per day of travel \n",
      "- Coverage includes:\n",
      "    - Medical: Emergency medical expenses, hospitalization, without coverage for COVID-19 related claims\n",
      "    - Personal accident: Accidental death or permanent disability\n",
      "- Suitable for domestic travel within your home country\n",
      "\n",
      "Please let me know if you have any other questions. \n",
      "\n",
      " Inference time: 0:00:05.003229\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78d63227-09c8-4ea6-bf13-712b837a934c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the details:\n",
      "\n",
      "The International Plan costs USD 10 per day and includes:\n",
      "- Travel inconvenience coverage like delayed or lost luggage reimbursement   \n",
      "- Medical coverage while traveling abroad including COVID protection\n",
      "- Personal accident coverage \n",
      "- Coverage for trip cancellation or interruption\n",
      "\n",
      "The Domestic Plan costs USD 3 per day and includes:\n",
      "- Medical coverage while traveling within your home country but without COVID coverage\n",
      "- Personal accident coverage \n",
      "\n",
      " Inference time: 0:00:01.284296\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa69b-0ec0-4837-a019-fb16fca9fb0e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80a21f-7987-40d0-b923-193c72367f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Generate content summary based on transcriptions from media files\n",
    "\n",
    "**Use Case:** A company needs to generate summaries of the audio transcription for audio and video files for customer service, to be sent to their operations quality team. They also want to classify this content according to specific categories.\n",
    "\n",
    "**Task:** Text Summarization & Text Classification\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d510-d20d-4820-96d6-156977876859",
   "metadata": {},
   "source": [
    "#### (Pre-requisite)\n",
    "\n",
    "First, we will need to transcribe the media files. You can e.g. use Amazon Transcribe for this task following examples like this: https://docs.aws.amazon.com/code-library/latest/ug/transcribe_example_transcribe_StartTranscriptionJob_section.html\n",
    "\n",
    "For our sample we will start from an interview transcription in the file \"interview.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edaa1e2c-6de3-4b24-805f-2090fd7909b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy Fallon: (00:00)\n",
      "Thank you for doing This Christmas Will Be Different. I appreciate you doing that. We hung out all day together.\n",
      "\n",
      "Matthew McConaughey: (00:04)\n",
      "How fun was that?\n",
      "\n",
      "Jimmy Fallon: (00:05)\n",
      "It was the greatest. We always…\n",
      "\n",
      "Matthew McConaughey: (00:07)\n",
      "Two take maximum. Two take maximum.\n",
      "\n",
      "Jimmy Fallon: (00:09)\n",
      "We nailed it, we have some good takes. That was so much fun. Happy holidays to you and your family. I’m happy to see you in person. Thanks for making the trip and being here.\n",
      "\n",
      "Matthew McConaughey: (00:18)\n",
      "Absolutely.\n",
      "\n",
      "Jimmy Fallon: (00:19)\n",
      "Do you have like family traditions? Do you have holiday plans? What do you have coming up?\n",
      "\n",
      "Matthew McConaughey: (00:24)\n",
      "This year, we’re going to get all the McConaughey family. We’re also getting Camila’s family. So when we do that and we have that multicultural Christmas, Christmas lasts a long time at our place because they celebrate on the 24th. Midnight you exchange presents. All right. So you have the big sit down dinner, you get the china out for the first time all year. If it was up to my family, it’d be paper plates. Thank you, Camila for getting the china out and having a better ritual.\n",
      "\n",
      "Jimmy Fallon: (00:50)\n",
      "No, we are using china.\n",
      "\n",
      "Matthew McConaughey: (00:51)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (00:52)\n",
      "Thank you, Camila.\n",
      "\n",
      "Matthew McConaughey: (00:53)\n",
      "We do that that night. And then we get up the next day and we do our Christmas, which is everyone opens present. Santa came. The problem, the reason I say it’s longer already is that my mother who’s 90 still demands that everyone open their present and everyone watch one person open their present at the time.\n",
      "\n",
      "Jimmy Fallon: (01:09)\n",
      "Yeah. Yeah.\n",
      "\n",
      "Matthew McConaughey: (01:10)\n",
      "You’ve got a big Brazilian family, you’ve got a big McConaughey family, there’s a family of 20. There’s a lot of presents, thankfully. It may be dark on the 25th when we’re done opening presents from that morning. And so seven o’clock PM and you just finished opening presents from Christmas morning. So the nights get long.\n",
      "\n",
      "Jimmy Fallon: (01:26)\n",
      "My grandma used to do this thing where we would unwrap the presents. She goes, can you just not rip it just so I can reuse the wrapping.\n",
      "\n",
      "Matthew McConaughey: (01:32)\n",
      "Save the wrapping.\n",
      "\n",
      "Jimmy Fallon: (01:33)\n",
      "Save the wrap for the next year. I go, yes, okay, grandma.\n",
      "\n",
      "Matthew McConaughey: (01:36)\n",
      "It’s 3:00 PM.\n",
      "\n",
      "Jimmy Fallon: (01:36)\n",
      "Let’s go. Let’s open up the thing. Yeah. It’s so fun. I look forward to it. Are you a guy that makes New Year’s resolutions?\n",
      "\n",
      "Matthew McConaughey: (01:43)\n",
      "Yeah. I check in on myself.\n",
      "\n",
      "Jimmy Fallon: (01:46)\n",
      "You check in on yourself.\n",
      "\n",
      "Matthew McConaughey: (01:49)\n",
      "I asked myself to work on my patience last year on New Year’s Eve.\n",
      "\n",
      "Jimmy Fallon: (01:55)\n",
      "We all need to do that.\n",
      "\n",
      "Matthew McConaughey: (01:57)\n",
      "And now thank you for reminding me, I guess tonight, I’ll start thinking about how I’ve done the last 11 months.\n",
      "\n",
      "Jimmy Fallon: (02:01)\n",
      "Exactly right. Well, I think last time we talked, I mean, congratulations, your book, Green Lights, was on the New York Times’ bestseller list 50, 5-0, 50 weeks. It sold like two and a half million copies. It is a giant, giant hit. But congratulations. I loved it.\n",
      "\n",
      "Matthew McConaughey: (02:18)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (02:19)\n",
      "Did you realize it would take off like that? I mean so many people.\n",
      "\n",
      "Matthew McConaughey: (02:22)\n",
      "I had no idea.\n",
      "\n",
      "Jimmy Fallon: (02:23)\n",
      "It’s massive.\n",
      "\n",
      "Matthew McConaughey: (02:24)\n",
      "It hit a nerve. Thank you everyone out there who had a read of it.\n",
      "\n",
      "Jimmy Fallon: (02:29)\n",
      "It was so honest and it was so… I loved it. I told you as soon as I read it, I couldn’t stop reading it. I go, oh, it’s so personal, but it’s so also universal.\n",
      "\n",
      "Matthew McConaughey: (02:39)\n",
      "Yep. I think that’s what people got from it. People said, hey, I see myself and you, I see my stories in your stories. And it kind of lays out a map of process. It’s a process book. It’s not a product book. It’s a approach to life with this rodeo we’re all trying to get through and trying to get our eight seconds on. How can we do our best to get it?\n",
      "\n",
      "Jimmy Fallon: (02:59)\n",
      "You’re coming out with a journal now, a companion journal to help people. Because I think you were saying in the book too, it’s tough when you write to just tell someone, hey, just write something down every day or every night.\n",
      "\n",
      "Matthew McConaughey: (03:12)\n",
      "A blank sheet of paper intimidates the heck out of us. Right?\n",
      "\n",
      "Jimmy Fallon: (03:15)\n",
      "It does.\n",
      "\n",
      "Matthew McConaughey: (03:15)\n",
      "But journaling or writing things down I’ve done it all my life and it’s how I wrote Green Lights the book. Immensely valuable. I mean, I write things down to forget. If you write them down, you can forget them because they’re in there. Don’t just go to the diary or the journal to write down when you’re frustrated and confused. Go to the journal to write down what you’re doing in life when you’re rolling, when you’re catching green lights, when you’re in the flow, because we will get out of flow again. And it’s nice to have a document to go back and go, hoo, what was I doing when I was cruising?\n",
      "\n",
      "Jimmy Fallon: (03:44)\n",
      "Yeah. When life was perfect there in that moment.\n",
      "\n",
      "Matthew McConaughey: (03:46)\n",
      "You see habits and you can change and recalibrate. But yeah, it’s a journal. I got little nudges along the way that kind of help you and ask you some questions to write your story. The book Green Lights was my story. This is for your story.\n",
      "\n",
      "Jimmy Fallon: (03:57)\n",
      "Ah, I love that buddy. That’s awesome. Congrats on that.\n",
      "\n",
      "Matthew McConaughey: (04:02)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (04:03)\n",
      "We also, you were nice enough to Zoom into us when we couldn’t get any guests anywhere. No one was allowed to travel or do anything, but there was talk of you maybe running for governor of Texas and you recently decided to not run for governor.\n",
      "\n",
      "Matthew McConaughey: (04:17)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (04:17)\n",
      "Can you walk us through that decision?\n",
      "\n",
      "Matthew McConaughey: (04:19)\n",
      "Well, it was a to two year consideration that I came to the decision really over the last couple of months. And I was asking myself the original question and trying to answer it, how and where and what can I do to be most useful to myself, to my family and to the most amount of people. The embassy, the category of politics came up and it’s a privileged one that I gave great consideration to. But at this point in my life are the things I’ve got a 13 year old, 11 year old and an eight year old, the life I’m living right now, the storytelling I want to keep doing, it’s not the category for me at this point in my life.\n",
      "\n",
      "Jimmy Fallon: (04:51)\n",
      "Still not ruling out future.\n",
      "\n",
      "Matthew McConaughey: (04:53)\n",
      "I’m not until I am.\n",
      "\n",
      "Jimmy Fallon: (04:55)\n",
      "Okay.\n",
      "\n",
      "Matthew McConaughey: (04:56)\n",
      "Someone told me that was a very McConaughey answer the other day.\n",
      "\n",
      "Jimmy Fallon: (04:59)\n",
      "Not until I am. It’s very, yeah.\n",
      "\n",
      "Matthew McConaughey: (05:02)\n",
      "I’ll be keeping an eye open for-\n",
      "\n",
      "Jimmy Fallon: (05:03)\n",
      "Because I know Texas loves you. And when we did the show from Texas, you were nice enough to come on the show and gosh, you’re beloved down there as well. You think people love you here, standing ovations. They love you there.\n",
      "\n",
      "Matthew McConaughey: (05:15)\n",
      "It’s a great state.\n",
      "\n",
      "Jimmy Fallon: (05:16)\n",
      "I know you put on a benefit concert. What’s [inaudible 00:05:20] We’re Texas. After that rough, awful, devastating…\n",
      "\n",
      "Matthew McConaughey: (05:25)\n",
      "Winter storm Uru came through. We’re not used to winter storms like that in Texas. Okay. We were a bit awkward. We weren’t prepared. And a lot of people were out of home. A lot of people were out of school. A lot of people needed some help because they didn’t know how to deal with it. And so we, my foundation, which is the Just Keep Livin Foundations, we got together and said, we’re not disaster relief, but want to be disaster relief. We said, let’s go. And I headed to Texas. I got on the phone, Camilla got on the phone. 100% of the people we called, whether it was companies who donated, whether it was musicians who came in, everybody was a yes in the first 30 seconds. We went down to Texas, put the show on. We raised over $7.7 million, which is still being put out to our community.\n",
      "\n",
      "Jimmy Fallon: (06:05)\n",
      "That’s how you do it right there. You just stepped up. And I go, oh my gosh, what do you know about putting on a live concert? You’re like, nothing.\n",
      "\n",
      "Matthew McConaughey: (06:12)\n",
      "It was like takes today. You get one take, two maximum, but let’s throw it together. Because you have to. Disaster relief, you have to move quickly because if you take your time to say, oh, this has got to be perfect. Something else is taking the front page news. There’s another disaster coming, you know? So you need to jump on it quickly and get everyone together and take advantage of trying to get people to give at that time when it is front page news and they know people need help.\n",
      "\n",
      "Jimmy Fallon: (06:36)\n",
      "I saw Hollywood Reporter named you philanthropist of the year with all the stuff you do to give back.\n",
      "\n",
      "Matthew McConaughey: (06:41)\n",
      "That was cool.\n",
      "\n",
      "Jimmy Fallon: (06:44)\n",
      "It’s good to be you, but it’s also great to give back and it’s great. You know what you do? You show up. Every time you always show up for me, but I think for anything. I know you’re a great dad.\n",
      "\n",
      "Matthew McConaughey: (06:56)\n",
      "Thank you. Try to. I think we all try to. I think we learn more and more as we age, we serve ourself when we do serve others. That is a reciprocity little exchange right there. And then also there’s ways to serve ourself and serve others at the same time and where those two meet when we’re filling our bank account and our souls account at the same time, we’re getting the quantity and the quality at the same time. Honey, ho.\n",
      "\n",
      "Jimmy Fallon: (07:20)\n",
      "That’s what I’m talking about. I want to talk about and show a clip from Sing 2. More with Matthew McConaughey when we come back. Everybody come on back.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"interview.txt\", \"r\").read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e6dea9-7ae5-42ae-8195-b670e36d1482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =f\"\"\"\n",
    "Human:\n",
    "Generate a summary of the transcription in the <transcription></transcription> XML tags below.\n",
    "Then, classify the mood of the participants according to the closest category within 'fully satisfied', 'satisfied', 'unsatisfied', 'fully unsatisfied', or 'neutral'.\n",
    "\n",
    "<transcription>\n",
    "{f}\n",
    "</transcription>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "770b5b1d-d553-4526-8892-ec9f4570f731",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "Jimmy Fallon and Matthew McConaughey discuss McConaughey's holiday plans, family traditions, and philanthropic work. McConaughey talks about celebrating Christmas with both his and his wife Camila's extended families, which results in long days of present opening and meals. Fallon and McConaughey bond over memories of saving wrapping paper and impatiently waiting to open presents with family. \n",
      "\n",
      "McConaughey discusses his decision not to run for Texas governor at this point to focus on his family and storytelling. However, he does not rule out running for political office in the future. McConaughey also talks about organizing a benefit concert that raised over $7 million for Texans affected by Winter Storm Uri. Fallon praises McConaughey for his philanthropic work and showing up to help others in times of need.\n",
      "\n",
      "Overall, the mood of the participants seems satisfied and content discussing family, charity work, and life events. The friendly, casual tone and laughter throughout the conversation indicates Fallon and McConaughey are fully satisfied with their discussion. \n",
      "\n",
      " Inference time: 0:00:09.338650\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d09320-6f1e-4596-8f51-55dfc0b127d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "- Jimmy Fallon and Matthew McConaughey discuss Matthew filming a Christmas song for Jimmy's show. They had fun filming it together.\n",
      "\n",
      "- Matthew talks about his family's Christmas traditions which involve both his and his wife's large extended families. They celebrate on Christmas Eve and Christmas Day, so the celebrations last a long time. \n",
      "\n",
      "- They discuss New Year's resolutions and Matthew says his resolution last year was to work on his patience. \n",
      "\n",
      "- Jimmy congratulates Matthew on the success of his book \"Green Lights\" which was a New York Times bestseller for 50 weeks and sold over 2.5 million copies. Matthew says he had no idea it would be so successful but it hit a nerve with people.\n",
      "\n",
      "- They discuss Matthew's new companion journal to his book to help people journal their own stories. \n",
      "\n",
      "- Matthew considered running for governor of Texas but recently decided not to run, citing his young children and wanting to focus on storytelling at this point in his life. \n",
      "\n",
      "- Matthew organized a benefit concert in Texas after a winter storm to raise money for disaster relief, which raised over $7 million.\n",
      "\n",
      "- In summary, the mood of the conversation seems 'fully satisfied'. The participants are enjoying their discussion, congratulating each other on successes, and discussing positive life events and charitable work in a cheerful manner. \n",
      "\n",
      " Inference time: 0:00:05.302026\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410031e-d47f-485f-b83e-cbdbbb2fa42b",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617cee-a8e9-4728-b821-6ebf2c6d51fc",
   "metadata": {},
   "source": [
    "## 5. Create splash pages describing upcoming promotions\n",
    "\n",
    "**Use Case:** A company wants to create HTML pages quickly and easily for their upcoming promotions.\n",
    "\n",
    "**Task:** Code Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e248a2a2-687b-40c5-aeed-e183bd181b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "There is an upcoming promotion presented by the Star Insurance company.\n",
    "The promotion is targeting young audience in the age range between 18 and 40 who drives a car.\n",
    "The promotion consists of a 20% discount when contracting the auto insurance policy.\n",
    "There will be additional discounts if the customer is coming from another insurance company.\n",
    "The promotion is part of the Summer Discounts of the company.\n",
    "The promotion is available from June 28th to August 31st.\n",
    "\n",
    "Based the this information, generate the HTML code for an attractive splash page for this promotion.\n",
    "Include catchy phrases and an attractive image of a car.\n",
    "Invite customers to contract the policy through a button in the portal.\n",
    "Have the splash page use red fonts and black background, according to the company's branding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2f4a927-6e7a-49fd-b253-6ee555b17fbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Here is the HTML code for the splash page:\n",
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Star Insurance Summer Promotion</title> \n",
       "<style>\n",
       "body {\n",
       "background-color: black;\n",
       "color: red; \n",
       "font-family: sans-serif;\n",
       "}\n",
       "h1 {\n",
       "font-size: 50px;\n",
       "}\n",
       "p {\n",
       "font-size: 20px;\n",
       "}\n",
       ".button {\n",
       "background-color: red;\n",
       "color: white;\n",
       "padding: 10px 20px;\n",
       "border-radius: 5px;\n",
       "}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<h1>20% OFF Auto Insurance!</h1>\n",
       "<p>This summer, get 20% off your auto insurance policy with Star Insurance.</p>\n",
       "<p>Additional discounts for switching from another company.</p> \n",
       "<p>Promotion valid June 28 - August 31.</p>\n",
       "<img src=\"car.jpg\" width=\"500\">\n",
       "<p><button class=\"button\">Get Your Discount Now!</button></p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbf6f2f2-601e-4da8-bf2f-ec1ef4840faf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "<body style=\"background-color:black;\">\n",
       "<center>\n",
       "<h1 style=\"color:red;\">Summer Car Insurance Deals!</h1>\n",
       "<img src=\"car.jpg\" alt=\"car\" width=\"500\" height=\"333\">\n",
       "<p style=\"color:red;\">Get up to 20% off your auto insurance policy with Star Insurance!</p> \n",
       "<p style=\"color:red;\">Switch from your current insurer and save even more!</p>\n",
       "<p style=\"color:red;\">Hurry, offer ends August 31st!</p>\n",
       "<button style=\"background-color:red; color:white;\">Get My Discount Now</button>\n",
       "</center>  \n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c45ec6-8934-4a2e-a53c-03ffa81ddd31",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
