{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4870e5-4286-46a4-88f5-042e52892ded",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Auto-Prompting for Generative AI with AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf825ce-ddfa-46b6-b1ed-d33f76114b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9c504e-666e-4dfe-87dc-c6982832bcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install ../dependencies/boto3-1.26.140-py3-none-any.whl --quiet\n",
    "#%pip install ../dependencies/botocore-1.29.140-py3-none-any.whl --quiet\n",
    "#%pip install langchain streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f84442-789a-426d-9308-f91f1e301c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "bedrock = boto3.client(\n",
    " service_name='bedrock',\n",
    " region_name='us-east-1',\n",
    " endpoint_url='https://bedrock.us-east-1.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86a208e8-4203-436a-baed-bf9b98caaeab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def load_chain():\n",
    "    llm = Bedrock(\n",
    "        model_id ='anthropic.claude-instant-v1',\n",
    "        #model_id='anthropic.claude-v1',\n",
    "        client=bedrock,\n",
    "        model_kwargs={\n",
    "            'max_tokens_to_sample':8000,\n",
    "            'temperature':0,\n",
    "            'top_p':0.9,\n",
    "            'stop_sequences': [\"Human\"]\n",
    "        }\n",
    "    )\n",
    "    memory = ConversationBufferMemory()\n",
    "    chain = ConversationChain(llm=llm, memory=memory)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59aa131b-1676-4251-a470-43f99ddcde9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatchain = load_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b79e249-9669-4501-bb93-dd27ddb9ad0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Human: ¿Qué es un gato?\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43331d25-e798-4d78-8397-11b6c9f1cb48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Un gato es un mamífero pequeño de la familia de los felinos. Tiene cuatro patas, pelaje suave, bigotes largos y una cola. Los gatos son animales domésticos muy populares que muchas personas tienen como mascotas. Ronronean, maúllan y les gusta dormir mucho durante el día. Cazan ratones y otros pequeños animales. Existen muchas razas de gatos, como el siamés, el persa y el gato común de pelo corto.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chatchain(user_input)[\"response\"]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd21db8b-f086-4d45-a756-c45c78feb14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Human: ¿Cuántas patas tiene?\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0db4795-db88-4552-9be5-f6616256fcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Un gato tiene cuatro patas.\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chatchain(user_input)[\"response\"]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35289388-612d-4ddb-9726-730d4c6cbf4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import Dict\n",
    "import json\n",
    "from io import StringIO\n",
    "from random import randint\n",
    "import boto3\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "st.set_page_config(page_title=\"Autoprompting\", page_icon=\":robot:\", layout=\"wide\")\n",
    "st.header(\"Auto-prompting - Create prompts for GenAI easily\")\n",
    "st.image('bedrock.png', width=80)\n",
    "# AUTHENTICATION\n",
    "import streamlit as st\n",
    "import streamlit_authenticator as stauth\n",
    "\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "with open('./config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=SafeLoader)\n",
    "\n",
    "authenticator = stauth.Authenticate(\n",
    "    config['credentials'],\n",
    "    config['cookie']['name'],\n",
    "    config['cookie']['key'],\n",
    "    config['cookie']['expiry_days'],\n",
    "    config['preauthorized']\n",
    ")\n",
    "name, authentication_status, username = authenticator.login('Login', 'main')\n",
    "if authentication_status:\n",
    "    # BEDROCK\n",
    "    session = boto3.Session(profile_name='bedrock')\n",
    "    \n",
    "    bedrock = session.client(\n",
    "            service_name='bedrock',\n",
    "            region_name='us-east-1',\n",
    "            endpoint_url='https://bedrock.us-east-1.amazonaws.com',\n",
    "    )\n",
    "    \n",
    "    @st.cache_resource\n",
    "    def load_chain(temperature):\n",
    "        llm = Bedrock(\n",
    "            #model_id ='anthropic.claude-instant-v1'\n",
    "            model_id='anthropic.claude-v1',\n",
    "            client=bedrock,\n",
    "            model_kwargs={\n",
    "                'max_tokens_to_sample':8000,\n",
    "                'temperature':temperature,\n",
    "                'top_p':0.9,\n",
    "                'stop_sequences': [\"Human\"]\n",
    "            }\n",
    "        )\n",
    "        memory = ConversationBufferMemory()\n",
    "        chain = ConversationChain(llm=llm, memory=memory)\n",
    "        return chain\n",
    "    \n",
    "    # this is the object we will work with in the ap - it contains the LLM info as well as the memory\n",
    "    temperature=0\n",
    "    chatchain = load_chain(temperature)\n",
    "    \n",
    "    # initialise session variables\n",
    "    if 'generated' not in st.session_state:\n",
    "        st.session_state['generated'] = []\n",
    "    if 'past' not in st.session_state:\n",
    "        st.session_state['past'] = []\n",
    "        chatchain.memory.clear()\n",
    "    if 'widget_key' not in st.session_state:\n",
    "        st.session_state['widget_key'] = str(randint(1000, 100000000))\n",
    "    st.sidebar.image('AWS_logo_RGB.png', width=100)\n",
    "    st.sidebar.write(f'Welcome *{name}*')\n",
    "    authenticator.logout('Logout', 'sidebar', key='unique_key')\n",
    "    st.sidebar.markdown(\"\"\"---\"\"\")\n",
    "    show_prompt = st.sidebar.checkbox('Show prompt')\n",
    "    input_prompt = ''\n",
    "    clear_button = st.sidebar.button(\"Clear Conversation\", key=\"clear\")\n",
    "    \n",
    "    st.markdown(\n",
    "        f'''\n",
    "            <style>\n",
    "                .sidebar .sidebar-content {{\n",
    "                    width: 150px;\n",
    "                }}\n",
    "            </style>\n",
    "        ''',\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "    \n",
    "    if clear_button:\n",
    "        st.session_state['generated'] = []\n",
    "        st.session_state['past'] = []\n",
    "        st.session_state['widget_key'] = str(randint(1000, 100000000))\n",
    "        chatchain.memory.clear()\n",
    "    \n",
    "    #Options...\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        role = st.selectbox(\n",
    "            'This bot should act as a...',\n",
    "            ('business person', 'data scientist', 'technical expert', 'kid', 'customer service agent', 'other'))\n",
    "        if role == 'other':\n",
    "            role = st.text_input('Custom selection:')\n",
    "    \n",
    "        contextual_info = st.text_input('Any contextual information for this bot?:')\n",
    "    \n",
    "        temp = st.checkbox('Responses should be creative (leave unchecked for factual responses)')\n",
    "        if temp:\n",
    "            temperature = 1\n",
    "        else:\n",
    "            temperature = 0\n",
    "        \n",
    "    with col2:\n",
    "        style = st.selectbox(\n",
    "            'The style or format of the response should be...',\n",
    "            ('formal', 'informal', 'simple', 'detailed', 'short', 'long', 'other'))\n",
    "        if style == 'other':\n",
    "            style = st.text_input('Custom selection:')\n",
    "    \n",
    "        language = st.selectbox(\n",
    "            'The language of this bot should be...',\n",
    "            ('english', 'spanish', 'portuguese', 'other'))\n",
    "        if language == 'other':\n",
    "            language = st.text_input('Custom selection:')\n",
    "    \n",
    "        guardrails = st.text_input('This bot should not respond to the following words or topics...')\n",
    "    \n",
    "    #--- Process prompt\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"role\", \"style\", \"language\", \"contextual_info\", \"guardrails\"], \n",
    "        template=\"\"\"\n",
    "        Context: {contextual_info}\n",
    "        Act as a {role}. Provide the answers in a {style} way. Provide the answers in {language}.\n",
    "        If the Human request includes the words or topics in the <guardrails></guardrails> XML tags, then just respond with the message 'Sorry, but I cannot respond to this.'.\n",
    "        <guardrails>\n",
    "        {guardrails}\n",
    "        </guardrails>\n",
    "        Human: {user_input}\n",
    "        Assistant:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # this is the container that displays the past conversation\n",
    "    response_container = st.container()\n",
    "    # this is the container with the input text box\n",
    "    container = st.container()\n",
    "    \n",
    "    with container:\n",
    "        # define the input text box\n",
    "        with st.form(key='my_form', clear_on_submit=True):\n",
    "            user_input = st.text_area(\"You:\", key='input', height=50)\n",
    "            submit_button = st.form_submit_button(label='Send')\n",
    "    \n",
    "        # when the submit button is pressed we send the user query to the chatchain object and save the chat history\n",
    "        if submit_button and user_input:\n",
    "            input_prompt = prompt.format(\n",
    "                role=role,\n",
    "                user_input=user_input,\n",
    "                style=style,\n",
    "                language=language,\n",
    "                contextual_info=contextual_info,\n",
    "                guardrails=guardrails\n",
    "            )\n",
    "            output = chatchain(input_prompt)[\"response\"]\n",
    "            st.session_state['past'].append(user_input)\n",
    "            st.session_state['generated'].append(output)\n",
    "    \n",
    "    # this loop is responsible for displaying the chat history\n",
    "    if st.session_state['generated']:\n",
    "        with response_container:\n",
    "            for i in range(len(st.session_state['generated'])):\n",
    "                message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"adventurer\", seed=10)\n",
    "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"bottts\", seed=123)\n",
    "    \n",
    "    if show_prompt and input_prompt:\n",
    "        st.sidebar.write('Prompt:\\n' + input_prompt)\n",
    "\n",
    "elif authentication_status is False:\n",
    "    st.error('Username/password is incorrect')\n",
    "elif authentication_status is None:\n",
    "    st.warning('Please enter your username and password')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f715d2f-15c8-4586-a785-d8fcc6e3b40d",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Now that our demo app is ready, you can run the following in a system terminal:\n",
    "\n",
    "```pip install -r auto-prompting-requirements.txt```\n",
    "\n",
    "```streamlit run app.py```\n",
    "\n",
    "and open https://d-n7e8ofehpjt6.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8501/ in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08f2af-2c21-437e-bef5-beeb00cde21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
